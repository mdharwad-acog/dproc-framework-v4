llm:
  provider: google
  model: gemini-2.5-flash-lite
  temperature: 0.7
  maxTokens: 8192
  fallback:
    provider: openai
    model: gpt-4-turbo

execution:
  queuePriority: normal
  timeoutMinutes: 30
  retryAttempts: 3
